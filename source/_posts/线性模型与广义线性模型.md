---
title: 线性模型与广义线性模型
urlname: dowq0khi
comments: true
mathjax: true
date: 2020-04-09 11:01:00
categories:
- 算法
tags:
- 算法
description: 线性回归是线性模型，逻辑回归是广义线性模型的代表
---

> Log Loss来源于最大似然估计

### 问题

给定数据集$\mathcal{D}=\{(\vec{x_1}, y_1),(\vec{x_2}, y_2)...(\vec{x_N}, y_N)\}$，学习模型$f(\vec{x})$

### 线性模型=线性回归

模型：$f(\vec{x})=\vec{w}\cdot{\vec{x}}+b$

损失函数：$L=\sum(\tilde{y}-\hat{y})^2$，其中$\tilde{y}$是标签，$\hat{y}$是预测值

学习方法：梯度下降，最小二乘

### 广义线性模型

选择单调可微函数$g(\cdot)$，令$g(y)=\vec{w}\cdot{\vec{x}}+b$

得到的$y=f(\vec{x})$就是一个广义线性模型

### 逻辑回归

逻辑回归是一种广义线性模型

模型：$f(\vec{x})=\frac{1}{1+e^{-(\vec{w}\cdot{\vec{x}}+b)}}$

损失函数：LogLoss

### SoftMax回归

SoftMax回归也是一种广义线性模型，用于解决K分类问题

模型：
$$
p(y=k|\vec{x})=\frac{e^{\vec{w_j}\cdot{\vec{x}}+b}}{1+\sum_{j=1}^{j=K-1}e^{\vec{w_j}\cdot{\vec{x}}+b}}, k=1,2,...,K-1 \\
p(y=K|\vec{x})=\frac{1}{1+\sum_{j=1}^{j=K-1}e^{\vec{w_j}\cdot{\vec{x}}+b}}
$$
损失函数：LogLoss

### 其他广义线性模型

1. 线性判别分析
2. 感知机